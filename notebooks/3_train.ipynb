{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from keras.models import Model, load_model\n",
    "from keras.applications import inception_v3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import losses, optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "RANDOM_SEED = 43\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (2992, 299, 299, 3)\n",
      "y_train.shape: (2992,)\n",
      "X_val.shape: (997, 299, 299, 3)\n",
      "y_val.shape: (997,)\n",
      "X_test.shape: (1000, 299, 299, 3)\n",
      "y_test.shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train, y_train = np.load('./data/X_train.npy'), np.load('./data/y_train.npy')\n",
    "X_val, y_val = np.load('./data/X_val.npy'), np.load('./data/y_val.npy')\n",
    "X_test, y_test = np.load('./data/X_test.npy'), np.load('./data/y_test.npy')\n",
    "print 'X_train.shape:', X_train.shape\n",
    "print 'y_train.shape:', y_train.shape\n",
    "print 'X_val.shape:', X_val.shape\n",
    "print 'y_val.shape:', y_val.shape\n",
    "print 'X_test.shape:', X_test.shape\n",
    "print 'y_test.shape:', y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess function\n",
    "def preprocess_im(im):\n",
    "    im = im.astype(np.float32)\n",
    "    im = inception_v3.preprocess_input(im)\n",
    "    return im\n",
    "\n",
    "# Preprocess validation\n",
    "X_val = inception_v3.preprocess_input(X_val.astype(np.float32))\n",
    "\n",
    "# Preprocess y\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np_utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.3714 - acc: 0.8375Epoch 00000: val_loss improved from inf to 0.18002, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 30s - loss: 0.3676 - acc: 0.8397 - val_loss: 0.1800 - val_acc: 0.9378\n",
      "Epoch 2/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9559Epoch 00001: val_loss improved from 0.18002 to 0.13065, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 23s - loss: 0.1548 - acc: 0.9555 - val_loss: 0.1307 - val_acc: 0.9609\n",
      "Epoch 3/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9678Epoch 00002: val_loss improved from 0.13065 to 0.10937, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 23s - loss: 0.1203 - acc: 0.9675 - val_loss: 0.1094 - val_acc: 0.9639\n",
      "Epoch 4/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9596Epoch 00003: val_loss did not improve\n",
      "\n",
      "Epoch 00003: reducing learning rate to 0.000330000015674.\n",
      "46/46 [==============================] - 23s - loss: 0.1169 - acc: 0.9591 - val_loss: 0.1436 - val_acc: 0.9549\n",
      "Epoch 5/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9700Epoch 00004: val_loss improved from 0.10937 to 0.10770, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 23s - loss: 0.1011 - acc: 0.9703 - val_loss: 0.1077 - val_acc: 0.9629\n",
      "Epoch 6/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9728Epoch 00005: val_loss improved from 0.10770 to 0.08040, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 23s - loss: 0.0883 - acc: 0.9731 - val_loss: 0.0804 - val_acc: 0.9789\n",
      "Epoch 7/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9765Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00006: reducing learning rate to 0.000108900003252.\n",
      "46/46 [==============================] - 23s - loss: 0.0827 - acc: 0.9763 - val_loss: 0.0935 - val_acc: 0.9699\n",
      "Epoch 8/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9704Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00007: reducing learning rate to 3.59369999205e-05.\n",
      "46/46 [==============================] - 22s - loss: 0.0910 - acc: 0.9703 - val_loss: 0.0894 - val_acc: 0.9719\n",
      "Epoch 00007: early stopping\n",
      "Top Model Train Done.\n"
     ]
    }
   ],
   "source": [
    "# ** Make model **\n",
    "# Base model\n",
    "base_model = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.33)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# ** Configuation **\n",
    "# Freeze layers (Only top trainable)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "loss = losses.categorical_crossentropy\n",
    "optimizer = optimizers.Adam()\n",
    "metrics = ['accuracy']\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "# Callbacks\n",
    "m_q = 'val_loss'\n",
    "model_path = './models/model_foodvsnot_v2.h5'\n",
    "check_pt = callbacks.ModelCheckpoint(filepath=model_path, monitor=m_q, save_best_only=True, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=1, monitor=m_q, verbose=1)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(patience=0, factor=0.33, monitor=m_q, verbose=1)\n",
    "callback_list = [check_pt, early_stop, reduce_lr]\n",
    "\n",
    "\n",
    "# ** Fit **\n",
    "# Data Generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,  \n",
    "                             rotation_range=15,\n",
    "                             fill_mode='reflect',                          \n",
    "                             preprocessing_function=preprocess_im)\n",
    "\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Fit\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(X_val, y_val),  \n",
    "                    epochs=99,\n",
    "                    steps_per_epoch=len(X_train)/batch_size,\n",
    "                    callbacks=callback_list)                    \n",
    "print 'Top Model Train Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train All Model - Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('./models/model_foodvsnot_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9760Epoch 00000: val_loss improved from inf to 0.05884, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 51s - loss: 0.0754 - acc: 0.9755 - val_loss: 0.0588 - val_acc: 0.9779\n",
      "Epoch 2/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9888Epoch 00001: val_loss improved from 0.05884 to 0.05426, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0356 - acc: 0.9890 - val_loss: 0.0543 - val_acc: 0.9809\n",
      "Epoch 3/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9924Epoch 00002: val_loss improved from 0.05426 to 0.05081, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0265 - acc: 0.9925 - val_loss: 0.0508 - val_acc: 0.9799\n",
      "Epoch 4/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9954Epoch 00003: val_loss improved from 0.05081 to 0.04130, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0218 - acc: 0.9951 - val_loss: 0.0413 - val_acc: 0.9840\n",
      "Epoch 5/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9958Epoch 00004: val_loss improved from 0.04130 to 0.03981, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0138 - acc: 0.9959 - val_loss: 0.0398 - val_acc: 0.9829\n",
      "Epoch 6/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9957Epoch 00005: val_loss improved from 0.03981 to 0.03668, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0367 - val_acc: 0.9840\n",
      "Epoch 7/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9979Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00006: reducing learning rate to 0.000330000015674.\n",
      "46/46 [==============================] - 39s - loss: 0.0094 - acc: 0.9980 - val_loss: 0.0373 - val_acc: 0.9829\n",
      "Epoch 8/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9969Epoch 00007: val_loss improved from 0.03668 to 0.03558, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 38s - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0356 - val_acc: 0.9840\n",
      "Epoch 9/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9990Epoch 00008: val_loss improved from 0.03558 to 0.03498, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0350 - val_acc: 0.9840\n",
      "Epoch 10/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979Epoch 00009: val_loss improved from 0.03498 to 0.03403, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0340 - val_acc: 0.9850\n",
      "Epoch 11/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9997Epoch 00010: val_loss improved from 0.03403 to 0.03334, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0057 - acc: 0.9997 - val_loss: 0.0333 - val_acc: 0.9850\n",
      "Epoch 12/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9988Epoch 00011: val_loss did not improve\n",
      "\n",
      "Epoch 00011: reducing learning rate to 0.000108900003252.\n",
      "46/46 [==============================] - 38s - loss: 0.0055 - acc: 0.9989 - val_loss: 0.0334 - val_acc: 0.9860\n",
      "Epoch 13/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9986Epoch 00012: val_loss improved from 0.03334 to 0.03306, saving model to ./models/model_foodvsnot_v2.h5\n",
      "46/46 [==============================] - 39s - loss: 0.0068 - acc: 0.9986 - val_loss: 0.0331 - val_acc: 0.9860\n",
      "Epoch 14/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9993Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00013: reducing learning rate to 3.59369999205e-05.\n",
      "46/46 [==============================] - 38s - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0333 - val_acc: 0.9860\n",
      "Epoch 15/99\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9957Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00014: reducing learning rate to 1.18592095896e-05.\n",
      "46/46 [==============================] - 38s - loss: 0.0114 - acc: 0.9958 - val_loss: 0.0332 - val_acc: 0.9860\n",
      "Epoch 00014: early stopping\n",
      "All Model Train Done.\n"
     ]
    }
   ],
   "source": [
    "# ** Configuation **\n",
    "# Open layers\n",
    "# for layer in model.layers[:249]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[249:]:\n",
    "#     layer.trainable = True\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model\n",
    "loss = losses.categorical_crossentropy\n",
    "optimizer = optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "metrics = ['accuracy']\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "# Callbacks\n",
    "m_q = 'val_loss'\n",
    "model_path = './models/model_foodvsnot_v2.h5'\n",
    "check_pt = callbacks.ModelCheckpoint(filepath=model_path, monitor=m_q, save_best_only=True, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=1, monitor=m_q, verbose=1)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(patience=0, factor=0.33, monitor=m_q, verbose=1)\n",
    "callback_list = [check_pt, early_stop, reduce_lr]\n",
    "\n",
    "\n",
    "# ** Fit **\n",
    "# Data Generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,  \n",
    "                             rotation_range=15,\n",
    "                             fill_mode='reflect',                          \n",
    "                             preprocessing_function=preprocess_im)\n",
    "\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Fit\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(X_val, y_val),  \n",
    "                    epochs=99,\n",
    "                    steps_per_epoch=len(X_train)/batch_size,\n",
    "                    callbacks=callback_list)                    \n",
    "print 'All Model Train Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Find Optimal Threshold\n",
    "\n",
    "Find optimal threshold by using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = load_model('./models/model_foodvsnot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 5s     \n"
     ]
    }
   ],
   "source": [
    "# Predict validation data\n",
    "p_val = model.predict(inception_v3.preprocess_input(X_val.astype(np.float32)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Threshold: 0.766766766767\n",
      "Max. Accuracy: 0.98294884654\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAF3CAYAAAALu1cUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4XHd97/HPV6PFkjc5XhRHtmPHseM4iW0SZYEEIvaE\nAmmAXEJpKbm0LpRQ8tyWC+3TS2/LvVxKCm36JMF1uWnYSigQINw6JAQQ2Ylt4thxvMTxEsuO90XW\nYmuZ7/1jRrI8HlkjWUfnN2fer+fxg2bmSPNFv0jno+/vd37H3F0AAACIT1ncBQAAAJQ6AhkAAEDM\nCGQAAAAxI5ABAADEjEAGAAAQMwIZAABAzAhkAAAAMSOQAQAAxIxABgAAEDMCGQAAQMzKo/rCZnaf\npHdL2uful+Z53STdJeldktolfdTdfzvY150yZYrPnj17hKs9XVtbm8aOHRv5+6BwjEl4GJMwMS7h\nYUzCNBrjsnr16gPuPnWw4yILZJLul3S3pG8O8PqNkuZl/10t6WvZ/z2j2bNna9WqVSNU4sCamprU\n2NgY+fugcIxJeBiTMDEu4WFMwjQa42JmOwo5LrIpS3d/XNKhMxxyk6RvesazkmrNbHpU9QAAAIQq\nzjVk9ZJ29nvcnH0OAACgpEQ5ZTlizGyppKWSVFdXp6ampsjfs7W1dVTeB4VjTMLDmISJcQkPYxKm\nkMYlzkC2S9LMfo9nZJ87jbsvl7RckhoaGnw05uGZ7w8PYxIexiRMjEt4GJMwhTQucU5ZPiTpI5Zx\njaSj7v5ajPUAAADEIsptL74rqVHSFDNrlvQ3kiokyd2XSVqhzJYXW5TZ9uK2qGoBAAAIWWSBzN0/\nNMjrLumTUb0/AABAsWCnfgAAgJgRyAAAAGJGIAMAAIgZgQwAACBmRbExLBCyjs4e7W05rtlTuHEw\nMBzptOu57YfU0dUz6LELzh2v6ROrh/T1O7vTem7bIXWl08Oqb1xVuRrOnyQzG9bnA4UgkAFn4O46\ndqK77/HTWw7ooRd2y/3kMSu3H9aB1hN680VTNaYi1fd8fW21PnPDRaoqT2moct93NI2vKi/aE0/r\niW6l3VVmpnFV+X+99aRdbZ3xfG8HsvtIh5Y/vlUdnScDybiqcv3J9XM1bULVkL9ee5er5XiXJGnD\n7hZ9+zevqrtneGEk1+tm1erWq2YN+/PdpW88vV0bXmvpe27bgTZt3HOsoM+vTJWp8aKpSpUV/t/o\n+t0tevVQ+5Br7e/S+gmaOalm0OPKU2X6g2vO14Lp4/ueq67I/zugvbNb3Wk/7fli/hnE8BHIkGhP\nvnxAG/e0DH7gAB5+cY9W7zh8ynNjK1Oqn3TyL/QxFZmZ/11HOvqec8987o5D7bp6zjlDft+HXtit\ntc1Hh1n12Vk4fYLed3lht5V9ZXuXtjyxNeKKCvPs1oN6bMO+vsfvWFinq3K+991p17ef3aHmwx25\nnx6EedPGySzz38/L+1r1/dXNw/9iv3i078OKlGnOCHRwD7V16uEX9+iLKzae9deaNr5KtTUVfY//\n5E0X6IZLzz3j5+w/dkJff3Kbth9sG9J71VSm9NkbFuiaC4b+s+iSHlqzW0+/ckCv7G8d9Pit+9v0\n0xd2n/LcOWMrdf1015bUyZ+VDa8d04+eb1aePKYlM2v17kXT+x6PH1Oum5bUn/IHH5LH3PP81xCw\nhoYGX7VqVeTvE9LtFErV8a6eU/6K/u1vf6vLL798kM9J676ntmnHwTZ1dqe1/eDZ/VVcXma6pWGm\n5k7NnMyqKlJ67+LzNLG6YpDPlO7+5cv6ys83azg/YpWpMn3wypk6f/Lgf5GPpObDHfr3515VZ/fI\ndFNG2+8smq7XzazV6h2H9fCLe/IeM76qXH/4htmnhIEQXD9/qubVneyqvLS7RU+/cmBYX+uVV17R\n3LlzJUllZnrXZdN17sQxZ11jT9r1kzW7dKit86y+zrQJY/SeRdMT2QV67WiHHl63R+nsD/7xrh7d\n//QOHWg9cdqx1104RY0XTT3lue0H2/S9lTvV1XPqL46J1RWqy+mWXnLeRP3+NbNUNsj3cfrE6mGN\n/8t7j6l1mJ36+knVmjb+7P+bi9ponOvNbLW7Nwx6HIEsPwJZfI4d79I9v3pFP3q+WXtbTv8lVog3\nzpuicVXlqpswRp9884Wqqhje9SsVZWWqrhz+X6VtJ7rVM4yfscpUWWx/DR/v6lFngdNbTz7xpK57\n43URV1SYlJnG9pumHOh7X1VeNqxp5GLC76+wdPWk9fNf/vqUnxWTNH5M/j8KOjp7Tlnv9vC619S0\naf8pxxxs7dRz2w8V9P6pMtNNi8/Tf71uji6tnyh317d/86pe2j1wF37HwXY9/crBgr5+PhUp0x1v\nm68/bZwbdPAOKZAxZYkB7TrSoae3DO8v9IFs2d+qbz+z44yLd3tb+LPOqdH/ePdCXZDtTq1bu1aX\nLVo06HvMqK0+pdMQp7EDrGMK2ZiKVMFhsKbCNGGAk0rcivF7j2SqSJUN6WelujKlap38GfzglbP0\nwStPX7e3rvmoDrSd+Y/W4509+r9PbtODz+/Sg8/vUpmd/B1bXZHS+DED/5zc/Lp6vXfxeZn0OASt\nx7v1z794WXc+skl7W47rsvqJmnVOja6+YPLQvlCJ4TdWieno7NGeluOSMgvHv7+6Wau3Hz7tOJfr\nhZ1HC+6UDMVFdeP1jkvqznjM1XMm67p5U055zl4rV+NF00a8HgAoRpfNmFjQcTdeNl27jnTo+6t2\nqiebxuomjNHvXTVLZUO4OGIo3r1ouv7i+2v1zWd29D13yXkTNLayXLLM6xv3HNOWva2aPK5SS990\ngWprKjXrnJohXbCRJASyErKv5bhuvvfpUxafS9IFU8aqbkLuXL/pjfOm6LZr54z4Oqb62urIfgkA\nAE5XX1utO942f9Tez8z0D7cs0p+/Y746unr0r49v1Y7smt4t+1v1+Z+slyTNrxun57Yf6lvzOXfq\nWN15y2JdPmvSqNUaCgJZiTje1aOl31qtQ22d+uLNl6kmuy5qYnWFrp8/lYAEABhRZqbzajNXpH/p\n/SeXm3R09uiXG/fpnLGVev3cydq4p0UbXzumLftadU/TFr3v3qc1qaaib+3ZNReco99dUq9FM2pH\n5OKUUBHIitDhtk7lLlVe23xEDzy3U91p14xJ1frcjQtUVV6mu37xsl7c1aI9LR16cVeLvvbhy3Xj\nZdPzfl0AAKJWXZnS7/Tb1mPBuRO04NwJkqQ/fMNsff2JrWrP7sm383C7VqzboxXr9qiyvExvmjdF\nb5o/VR95/ew4So8UgSwwnd1pPfjbZh3p6Mr7+uOb9w945cuYijLNmTJOj23Yq52H2jVpbKV+sLpZ\nF04bp8pUmf7upksIYwCAYE0dX6W/fNfFpzy3/UCbNu89pvue2qYXd7XosQ37NHNSjd68IFlriglk\ngdi4p0XfemaHfvrCbrUcH3jflzKTbrlihi6tP3UxZ1mZ6YZLztXU8VX6WtMruvORjUq79KGrZumL\nN18a9GXHAAAMZPaUsZo9Zazeccm52rLvmN721ce19FurdOcHFuumJecl5vxGIIvRT9bs0hMvH9Cu\nwx16Zmum67V4Zq1uuWKG3n/5jLyfY6ZBtyT4RONc3XbtbEmDHwsAQLG4cNp4rfrrt+m/LHtGd3xv\njb63cqe+/IFFmnnO6G6iHQUCWcTaTnRrxbrXTrtf2b6WE/rHxzZr8thKjalI6ebX1esjrz9fS2bW\njkjaJ4gBAJJoyrgq/fj2a3XnzzbpW8/u0Bu//Cvd+YFFuqVhZtylnRUCWYTcXf/rPzfou8+9mvf1\nK2dP0rc+djXhCQCAIZgwpkJf+N1L9eFrZun2f39eX3p4oz5wxYyinr4kkEWg+XC7vvObV/XCziN6\n+pWDun7+VP39+0/fYX7a+Cq2mwAAYJgWnDtBH33DbP31j19U8+GOop66JJCNsHTa9bH7V2nT3mMa\nV1WuW66Yof9+wwJNHV81+CcDAIAhWTyjVpL0nruf1N++9xLdtKQ+5oqGh0A2grp70vrUd5/Xpr3H\ndNetS4r2PwoAAIrFJedN0GfeeZF+uLpZf/XgOr1lwbQBb9wesrK4C0iS+5/erodf3KNrL5ysGy9l\nvy8AAKJWVmb65Jsv1Fc/uERtnT36WtMrcZc0LASyEXLseJf+7antunrOOfrOH12jynK+tQAAjJYl\nM2v1vtfV618e36q9LcfjLmfISA0j5M//4wXtaTmu//b20bt5KwAAOOnTb5snd9f/WbEh7lKGjEA2\nAnYeatejL+3Vp95yoa6+YHLc5QAAUJLOnzxWH7tujn7ywm4dbD0RdzlDQiAbAY+s3yNJevci1o0B\nABCn31l0ntylbz/7qnpyNmUPGYHsLJ3o7tFXf75ZV885R3Onjou7HAAAStpl9RO1eMZE/eNjm/Vv\nT22Lu5yCEcjO0obXjqm9s0e3XTu7qHcIBgAgCVJlpu/88TUaU1GmxzbsjbucghHIzoK765cb90mS\nFmU3pgMAAPEaV1WuP7ruAj237ZCaNu2Lu5yCEMiGyd31mR+s1T//4mVdPqtW0yeOibskAACQ9adv\nnqsF507QHd9bo87udNzlDIpANkzLfr1VP1jdrFuumKF/++hVTFcCABCQmspy3fG2eTrS3qXVOw7H\nXc6gCGTD8Pjm/fryIxv1nsXn6csfWKSJNcV3iwYAAJLu9XMnK1VmevqVA3GXMigC2TD8+Pldmjy2\nUl9+/yI6YwAABGr8mArNmzZOa3YeibuUQRHIhmHzvmO6ePoEVVem4i4FAACcweIZtXph5xG1nuiO\nu5QzIpANUXdPWlv2tWretPFxlwIAAAbxvsvrdexEt+4PfE8yAtkQ3dv0io53pXXthdwiCQCA0F19\nwWTV11br5X2tcZdyRgSyIejqSeubz2zXWxdM01svrou7HAAAUIDzJ9do+8H2uMs4IwLZEGzd36YD\nrZ16z+Lz4i4FAAAU6PzJY/Xqwba4yzgjAtkQbN57TJI0v471YwAAFIt508bpcHuXmg+H2yUjkA3B\ny3uPqcykC6aOjbsUAABQoOsunCJJenxzuPuREcgK5O762fo9urR+osZUsN0FAADF4sJp4zR7co1+\n9Hxz3KUMiEBWoOe2HdLmva36/avPj7sUAAAwBGam918+Qyu3H9bR9q64y8mLQFagH6/ZpfFV5Szo\nBwCgCM0/N7P+e8ehMBf3E8gK9OKuFi2eWcvu/AAAFKHzJ9dIknYEuv0FgawA3T1pbdp7TBdP5+pK\nAACK0axzegMZHbKite1Amzq707p4+oS4SwEAAMNQU1muGZOqtWHPsbhLyYtAVoCXXmuRJC04l0AG\nAECxWjRjotY2H4m7jLwIZAXY8NoxVaRMF04bF3cpAABgmC6rr9XOQx060t4ZdymnIZAVYOX2Q1o4\nfYIqy/l2AQBQrBZkr7QM8UbjJIxBHDvepTU7j+hN86fGXQoAADgLvTNdL+8lkBWdVw+1qyftWsiC\nfgAAilp9bbXGVJRp6/4SC2RmdoOZbTKzLWb2uTyvTzKzH5nZWjN7zswujbKe4TjQmplnnjq+KuZK\nAADA2SgrM00ZV6UDrSfiLuU0kQUyM0tJukfSjZIWSvqQmS3MOeyvJK1x90WSPiLprqjqGa79xzKD\nRiADAKD4TR5bqYNtpbWo/ypJW9x9q7t3SnpA0k05xyyU9EtJcveNkmabWV2ENQ1Zb4qeMo5ABgBA\nsZs8rkqHSiyQ1Uva2e9xc/a5/l6Q9D5JMrOrJJ0vaUaENQ3Z/mMnVFOZ0tiq8rhLAQAAZ+mcsZVB\nBrK4U8aXJN1lZmskrZP0vKSe3IPMbKmkpZJUV1enpqamyAtrbW1VU1OT1m05rnHl6VF5T5xZ75gg\nHIxJmBiX8DAm4Wg71Kn9LV361a9+pba2tmDGJcpAtkvSzH6PZ2Sf6+PuLZJukyQzM0nbJG3N/ULu\nvlzScklqaGjwxsbGaCrup6mpSY2Njfrqi0/qovoKNTZeHfl74sx6xwThYEzCxLiEhzEJxyZ7RQ9v\n26gr3/BGrXrmyWDGJcopy5WS5pnZHDOrlHSrpIf6H2BmtdnXJOmPJD2eDWnB2HGwve8O8QAAoLj1\nLkFqP9EdcyWniqxD5u7dZna7pEckpSTd5+7rzezj2deXSbpY0jfMzCWtl/SxqOoZjiPtnTra0aXz\nzxkbdykAAGAEVFekJEntnaetkIpVpGvI3H2FpBU5zy3r9/EzkuZHWcPZ2NuSucJyeu2YmCsBAAAj\noaYyE8g6usIKZOzUfwa9Nx+tra4c5EgAAFAMqivD7JARyM7gaEeXJKm2piLmSgAAwEjonbLsIJAV\njyPZQDaxmkAGAEAS1FRmVmsxZVlEjrZnAxkdMgAAEqG6MhN92jvDusqSQHYGRzu6lCozjWeXfgAA\nEqE62yE7ToeseBzp6NSEMeXK7FkLAACKXU2g214QyM7gcHuXamu4whIAgKSoZtuL4rOv5bimja+K\nuwwAADBCqsrLZMZVlkVlb8sJ1U1gU1gAAJLCzFRdkWLKsli4u/a0HNe5EwlkAAAkyZiKlDq703GX\ncQoC2QDauqTO7jRTlgAAJExFyghkxaKl0yVJUwlkAAAkSkWqTF09BLKicLwnE8jGsQcZAACJUlle\npk4CWXE4kd3At/fyWAAAkAyVdMiKx4lsh6z3nlcAACAZMlOWHncZpyCQDeBE9mrYsXTIAABIFBb1\nF5HeDhlTlgAAJEtFijVkRaO3Q8aUJQAAyVJZzhqyonFyDRkdMgAAkoRF/UXkRI9klrnnFQAASI6K\nVBlryIrFiW5XTUVKZhZ3KQAAYARVlHOVZdE40SPVsCksAACJU0mHrHic6HHWjwEAkECV5cYasmLR\nlWb9GAAAScS9LItIdzozYAAAIFlY1F9EelwqJ5ABAJA4lSzqLx49aVdFGVdYAgCQNL079buHE8oI\nZAPocaYsAQBIospUpuESUpOMxDGA7rRUnqJDBgBA0vQ2XEJaRkYgGwAdMgAAkolAVkR60q4KOmQA\nACROKrtGPKAZSwLZQLq5yhIAgEQjkBWBnrS4yhIAgAQK8TbVBLIBsA8ZAAAJF1CLjMQxAHbqBwAg\nmXobZAHlMQLZQHqcRf0AACRSgHOWBLIB9KSl8jK+PQAAJJUH1CMjcQygx6WK8vASNAAAODt9Z/dw\n8hiBbCDdaamCDhkAAIkT4IwlgSyfdDrTxOTWSQAAJFdADTICWT5d6cy9FLjKEgCA5DGF13AhceTR\nlb39O1dZAgCA0UAgy6O7J9Mh4ypLAACSp3cNGVOWgaNDBgBAcoV4dieQ5dHVwxoyAACSzgNqkZE4\n8ujOdsi4lyUAAMnDthdF4uRVlgGOGAAAOCtcZVkk+jpkLOoHACCxApqxJJDl053tkKXKwkvQAADg\nLAV4eieQ5ZHNYwQyAAASjEX9gUtnR4g8BgBA8oR4eieQ5dHTG8hIZAAAJI4FeJllpIHMzG4ws01m\ntsXMPpfn9Ylm9lMze8HM1pvZbVHWU6h0OhPIUgEOGAAAGBkBzVhGF8jMLCXpHkk3Sloo6UNmtjDn\nsE9KesndF0tqlPQVM6uMqqZC9fQGMjpkAAAkTohn9yg7ZFdJ2uLuW929U9IDkm7KOcYljbdM73Cc\npEOSuiOsqSB9U5Z0yAAAwCiIMpDVS9rZ73Fz9rn+7pZ0saTdktZJ+rS7pyOsqSBcZQkAQHL13Vw8\noDnL8pjf/52S1kh6i6S5kn5uZk+4e0v/g8xsqaSlklRXV6empqZIi1q3P9Oke2HN82rfkYr0vVC4\n1tbWyMceQ8OYhIlxCQ9jEpaNuzPn+fb29mDGJcpAtkvSzH6PZ2Sf6+82SV9yd5e0xcy2SVog6bn+\nB7n7cknLJamhocEbGxujqjnzfhv3SatXquGKy/W6WZMifS8UrqmpSVGPPYaGMQkT4xIexiQsh59v\nlta+oOqammDGJcopy5WS5pnZnOxC/VslPZRzzKuS3ipJZlYn6SJJWyOsqSAs6gcAILlCvJdlZB0y\nd+82s9slPSIpJek+d19vZh/Pvr5M0hck3W9m65S56OGz7n4gqpoKxaJ+AACSK8TTe6RryNx9haQV\nOc8t6/fxbknviLKG4XACGQAAiRfSon526s+jh6ssAQDAKCKQ5dE7ZZniuwMAQGIF1CAjkOXTe+sk\npiwBAEiekruXZbHiKksAAJIrxLM7gSwPrrIEACD5mLIMXJoOGQAAidXXbwkokRHI8ji5qJ9ABgAA\nokcgy4NF/QAAJFfvTv0BNcgIZPmwqB8AgOQKsd9CIMsjm8dEHgMAILnokAUu3XuVJYkMAIDECfHs\nTiDLo2/KMsSeJgAAOCshnt4JZHlwlSUAAMnnAd1dnECWB1dZAgCQZOGd3wlkefSkM/9LhwwAgOQK\npz9GIMvr5K2TYi4EAACMuBAnwAhkeaTTLlOYd4MHAABnJ8SzO4Esjx53umMAACRcQGv6CWT5pNME\nMgAAkirEGTACWR5p9yDnlwEAwNkL8RRfcCAzs+vM7Lbsx1PNbE50ZcWrJ01SBQAg6QKasSwsd5jZ\n30j6rKS/zD5VIenbURUVtzRryAAASKwQZ8EKbQTdLOm9ktokyd13SxofVVFx62ENGQAAiVd0HTJJ\nnZ65v4BLkpmNja6k+HGVJQAAydXXIQsokRUayP7DzP5FUq2Z/bGkxyT9a3RlxStzlSWJDACAJLIA\nl/WXF3KQu/+Dmb1dUoukiyR93t1/HmllMWLKEgCA5AuoQTZ4IDOzlKTH3P3NkhIbwvrrcQ8wOwMA\ngBER4El+0ClLd++RlDaziaNQTxDYGBYAgOQrqg5ZVqukdWb2c2WvtJQkd/+zSKqKWY9zY3EAAJKq\n7xQfUCIrNJA9mP1XEtipHwCA5Arx1kmFLur/hplVSpqffWqTu3dFV1a8mLIEACD5AmqQFRbIzKxR\n0jckbVem0zfTzP7Q3R+PrrT49KSdWycBAJBQIfZcCp2y/Iqkd7j7Jkkys/mSvivpiqgKi5MrzHYm\nAAA4eyGe4gttBFX0hjFJcvfNytzPMpE8pB4mAACIREin+0I7ZKvM7Os6eUPxD0taFU1JIWAfMgAA\nkqpod+qX9AlJn5TUu83FE5LujaSiALiH2c4EAAAjJ6QZsUIDWbmku9z9q1Lf7v1VkVUFAAAQkRCb\nLoWuIfuFpOp+j6uVucF4IgUUmAEAwAgLMI8VHMjGuHtr74PsxzXRlBQ/516WAAAkXkgNmEIDWZuZ\nXd77wMwaJHVEU1L8XGGmZwAAMAKyJ/liXEN2h6Tvm9nu7OPpkj4YTUnxcxIZAACJFeJVlmfskJnZ\nlWZ2rruvlLRA0vckdUn6maRto1BfLMhjAABgNA02ZfkvkjqzH79e0l9JukfSYUnLI6wrVh5SDxMA\nAIyoEK+yHGzKMuXuh7Iff1DScnf/oaQfmtmaaEuLV4BjBQAARlBI7ZfBOmQpM+sNbW+V9Mt+rxW6\n/qwohZieAQDA2QvxFD9YqPqupF+b2QFlrqp8QpLM7EJJRyOuLTbMWAIAkFwWYNfljIHM3f+3mf1C\nmasqH/WTi6vKJH0q6uLi4kE1MQEAQBRCasAMOu3o7s/meW5zNOWEwT3MdiYAADh7ATbICt4YtqRw\nc3EAAJIvoAYZgSwfpiwBAEiukz2XcM73BLI8mLIEACC5QpwFI5DlEU5eBgAAUQlpUT+BLB/WkAEA\nkGCZk3xAeSzaQGZmN5jZJjPbYmafy/P6Z8xsTfbfi2bWY2bnRFlTochjAAAkU4hNl8gCmZmllLnv\n5Y2SFkr6kJkt7H+Mu9/p7kvcfYmkv5T06363aooNi/oBAMBoirJDdpWkLe6+1d07JT0g6aYzHP8h\nZe4MELuQ5pQBAMDICrBBFmkgq5e0s9/j5uxzpzGzGkk3SPphhPUUzBVmOxMAAIyckPovodwg/D2S\nnhpoutLMlkpaKkl1dXVqamqKtJijRzuUUk/k74OhaW1tZUwCw5iEiXEJD2MSlq1HeiRJHR3HgxmX\nKAPZLkkz+z2ekX0un1t1hulKd18uabkkNTQ0eGNj4wiVmN9dLz2lzrYWRf0+GJqmpibGJDCMSZgY\nl/AwJmGZtPOI9OxTGjNmTDDjEuWU5UpJ88xsjplVKhO6Hso9yMwmSrpe0k8irGVIMhvDMmcJAABG\nR2QdMnfvNrPbJT0iKSXpPndfb2Yfz76+LHvozZIedfe2qGoZKpfCXPEHAADOWojrxCNdQ+buKySt\nyHluWc7j+yXdH2UdwxHgWAEAgBEU0qJ+durPh30vAABIrBCXJRHI8nDRIQMAIKlCnLIkkOXhJDIA\nABIvpAkxAlkeLiePAQCQcAHlMQJZPiElZgAAMLKYsiwSmX3IAAAARgeBLA/uZQkAQHJxlWWRcOYs\nAQBIvJBO9wSyAYSXnQEAwEjonQULKI8RyAAAQGkJcVkSgSwP9zAHCwAAJBOBLA8PqokJAABGUu+i\n/pDO9gSyPNj2AgCA5ApxFoxAlkdIiRkAAEQkoBM+gSwPdw8yPQMAgLMX4imeQJYH9xYHACD5AmqQ\nEcgAAEBpYR+yYhHSCAEAgBEW3jwYgSwPpiwBACgBATVgCGR5sKgfAIDkCvEcTyDLI6DADAAAIhLS\n+Z5AlgcbwwIAkFy953gCWeBcJDIAAJLKApyzJJDlkemQhTdYAAAgmQhkeTBlCQBAcvVNWXo4k5YE\nMgAAUFICnLEkkAEAAMSNQJYH+5ABAJBcIa4TJ5DlwU79AAAkXzgryAhkeQW0xg8AAIywvpuLB3S+\nJ5Dl4WLKEgAAjB4CWR4hJWYAAJB8BLI8WEMGAEBy9U1ZxlvGKQhkAyCQAQCQTNw6qUgwZQkAQPKF\ndLonkOXFvZMAAEiqEE/xBLI8uJclAAAlIKAWGYEsDxb1AwCQXCzqLxJOiwwAgMTi1klFgg4ZAAAY\nTQSyPLjKEgCA5Apw1wsC2UACHCsAADCCQmrAEMjy8JBGCAAAjKjepktIZ3sCWR6uMNuZAABgBAR4\njieQ5RNSZAYAAIlHIMuDqywBAEiu3m0vQuq/EMjycHcCGQAACRXisiQCWR4u0SIDACDhQrqGj0CW\nBxv1AwA9j8HWAAAMmklEQVSQXCGe4wlkeTiryAAAwCgikA0gxPllAABw9sxY1F8UQppTBgAAIyvE\nnkukgczMbjCzTWa2xcw+N8AxjWa2xszWm9mvo6ynUExYAgBQAgJqwJRH9YXNLCXpHklvl9QsaaWZ\nPeTuL/U7plbSvZJucPdXzWxaVPUMSUADBAAARlaIy5Ki7JBdJWmLu291905JD0i6KeeY35P0oLu/\nKknuvi/CegrmYh8yAACSLqT+S5SBrF7Szn6Pm7PP9Tdf0iQzazKz1Wb2kQjrKZh7mOkZAACcvRB3\n6o9synII73+FpLdKqpb0jJk96+6b+x9kZkslLZWkuro6NTU1RVpU2l2dnZ2Rvw+GprW1lTEJDGMS\nJsYlPIxJWNq6MlGs88SJYMYlykC2S9LMfo9nZJ/rr1nSQXdvk9RmZo9LWizplEDm7sslLZekhoYG\nb2xsjKrmjEf+U1WVlYr8fTAkTU1NjElgGJMwMS7hYUzCcrSjS/rFo6qsqgpmXKKcslwpaZ6ZzTGz\nSkm3Snoo55ifSLrOzMrNrEbS1ZI2RFhT4ZiyBAAgkXqXJYW0zVVkHTJ37zaz2yU9Iikl6T53X29m\nH8++vszdN5jZzyStlZSW9HV3fzGqmgoV0PgAAIARFmLPJdI1ZO6+QtKKnOeW5Ty+U9KdUdYxVNzL\nEgCA5AupAcNO/QMgkAEAkEwW4FYKBLIcHtKEMgAAKAkEshy9eSzA8AwAAEZA7yneA5q0JJDl6B0a\n8hgAAMkUYtOFQJaDKUsAAEpEQKd8AlmOvg5ZgOkZAACcvRBvnUQgAwAAJSXEpguBLAczlgAAlIaQ\nTvkEshy9V1wEGJ4BAEBCEchy9G17EW8ZAAAgagG1yAhkAyGRAQCQSH03F4+3jFMQyHLQIQMAINks\nwLM8gSwHa8gAACgNdMgC5mzVDwBAorHtRREJsZ0JAACSiUCWI6T2JQAAGHl9NxcP6KRPIMvBvSwB\nAEg2C3DOkkCWgyVkAABgtBHIcvRte0EiAwAgkfqmLGOt4lQEslwhjQ4AABhxITZdCGQ52IcMAIDS\nENKycQJZDnbqBwAg2VjUXwT6wnJ4YwUAABKKQDYA8hgAAMkW0IwlgSwX+5ABAJB8oc1aEshyEMcA\nACgNIZ3zCWQ52IcMAIDkMymoREYgy8G2FwAAJF9oV1oSyHIFlJYBAEB0QjrlE8hycC9LAACSL7Tz\nPIEsB2vIAADAaCOQAQCAkmPGrZOC5kHNKAMAgChYYJOWBLIc3MsSAIDSEFILhkCWg3tZAgBQAgI7\nzxPIcvTeOimwcQIAAAlGIMvBlCUAAMlnYsoSAAAgVqFtb0Ugy8E+ZAAAlAa2vQgY97IEACD5LLBJ\nSwIZAAAoOaHNhBHIcoTUvgQAANEJ6ZRPIMvRd3Px0KIzAAAYMaGd5QlkOZwWGQAApSGgUz6BLEdf\nhyzWKgAAQJTMLKQ8RiDLxcawAAAkX2jneQLZaUhkAACUAjpkAaNDBgBACQjsRE8gG0Bg4wQAABKM\nQJYjpPYlAACIhimsvUcJZDmcyywBAEi80PYbJZDl4F6WAACUhoAaZNEGMjO7wcw2mdkWM/tcntcb\nzeyoma3J/vt8lPUUIqT2JQAAiEZgDTKVR/WFzSwl6R5Jb5fULGmlmT3k7i/lHPqEu787qjqGiqss\nAQBIvtDO81F2yK6StMXdt7p7p6QHJN0U4fuNiL4py9BGCgAAjKiQJsWiDGT1knb2e9ycfS7XG8xs\nrZk9bGaXRFhPQSpSZTpv4hhVsroOAIDECm1Rf2RTlgX6raRZ7t5qZu+S9GNJ83IPMrOlkpZKUl1d\nnZqamiIt6ouvT6m1tTXy98HQMCbhYUzCxLiEhzEJT1dnp7o6PZhxiTKQ7ZI0s9/jGdnn+rh7S7+P\nV5jZvWY2xd0P5By3XNJySWpoaPDGxsbIiu7V1NSk0XgfFI4xCQ9jEibGJTyMSXjetOu3qu0+GMy4\nRDkxt1LSPDObY2aVkm6V9FD/A8zsXMv2DM3sqmw9ByOsCQAAQPd8+HK9/fyKuMvoE1mHzN27zex2\nSY9ISkm6z93Xm9nHs68vk/QBSZ8ws25JHZJudWfjCQAAUFoiXUPm7iskrch5blm/j++WdHeUNQAA\nAISOawkBAABiRiADAACIGYEMAAAgZgQyAACAmBHIAAAAYkYgAwAAiBmBDAAAIGYEMgAAgJgRyAAA\nAGJGIAMAAIgZgQwAACBmVmz38jaz/ZJ2jMJbTZF0YBTeB4VjTMLDmISJcQkPYxKm0RiX89196mAH\nFV0gGy1mtsrdG+KuAycxJuFhTMLEuISHMQlTSOPClCUAAEDMCGQAAAAxI5ANbHncBeA0jEl4GJMw\nMS7hYUzCFMy4sIYMAAAgZnTIAAAAYlbSgczMbjCzTWa2xcw+l+d1M7N/zr6+1swuj6POUlPAuHw4\nOx7rzOxpM1scR52lZLAx6XfclWbWbWYfGM36SlUh42JmjWa2xszWm9mvR7vGUlPA76+JZvZTM3sh\nOya3xVFnKTGz+8xsn5m9OMDrQZzrSzaQmVlK0j2SbpS0UNKHzGxhzmE3SpqX/bdU0tdGtcgSVOC4\nbJN0vbtfJukLCmgNQBIVOCa9x/29pEdHt8LSVMi4mFmtpHslvdfdL5F0y6gXWkIK/Fn5pKSX3H2x\npEZJXzGzylEttPTcL+mGM7wexLm+ZAOZpKskbXH3re7eKekBSTflHHOTpG96xrOSas1s+mgXWmIG\nHRd3f9rdD2cfPitpxijXWGoK+VmRpE9J+qGkfaNZXAkrZFx+T9KD7v6qJLk7YxOtQsbEJY03M5M0\nTtIhSd2jW2ZpcffHlfk+DySIc30pB7J6STv7PW7OPjfUYzCyhvo9/5ikhyOtCIOOiZnVS7pZdJFH\nUyE/K/MlTTKzJjNbbWYfGbXqSlMhY3K3pIsl7Za0TtKn3T09OuVhAEGc68tH+w2BkWJmb1YmkF0X\ndy3QP0n6rLunM3/4IxDlkq6Q9FZJ1ZKeMbNn3X1zvGWVtHdKWiPpLZLmSvq5mT3h7i3xloW4lXIg\n2yVpZr/HM7LPDfUYjKyCvudmtkjS1yXd6O4HR6m2UlXImDRIeiAbxqZIepeZdbv7j0enxJJUyLg0\nSzro7m2S2szscUmLJRHIolHImNwm6Uue2XNqi5ltk7RA0nOjUyLyCOJcX8pTlislzTOzOdkFlbdK\neijnmIckfSR7BcY1ko66+2ujXWiJGXRczGyWpAcl/QF/6Y+KQcfE3ee4+2x3ny3pB5L+lDAWuUJ+\nh/1E0nVmVm5mNZKulrRhlOssJYWMyavKdCxlZnWSLpK0dVSrRK4gzvUl2yFz924zu13SI5JSku5z\n9/Vm9vHs68skrZD0LklbJLUr85cNIlTguHxe0mRJ92Y7Mt2h3Bw2iQocE4yyQsbF3TeY2c8krZWU\nlvR1d8976T/OXoE/K1+QdL+ZrZNkykz1H4it6BJgZt9V5orWKWbWLOlvJFVIYZ3r2akfAAAgZqU8\nZQkAABAEAhkAAEDMCGQAAAAxI5ABAADEjEAGAAAQMwIZgOCZ2WQzW5P9t8fMdmU/PmJmL0Xwfo1m\n9v+G+DlNZnba9itm9lEzu3vkqgOQRAQyAMFz94PuvsTdl0haJukfsx8vUWZ/rTMys5LdcxFAcSCQ\nASh2KTP7VzNbb2aPmlm11Nex+iczWyXp02Y21cx+aGYrs/+uzR53fb/u2/NmNj77dceZ2Q/MbKOZ\nfceyuxCb2Vuzx60zs/vMrCq3IDO7zcw2m9lzkq4dpe8DgCJGIANQ7OZJusfdL5F0RNL7+71W6e4N\n7v4VSXcp01m7MnvM17PH/IWkT2Y7bm+U1JF9/nWS7pC0UNIFkq41szGS7pf0QXe/TJm7nXyifzFm\nNl3S3yoTxK7Lfj4AnBGBDECx2+bua7Ifr5Y0u99r3+v38dsk3W1ma5S5d90EMxsn6SlJXzWzP5NU\n6+7d2eOfc/dmd09LWpP9uhdl36/3HqrfkPSmnHqultTk7vvdvTOnBgDIi3UVAIrdiX4f90iq7ve4\nrd/HZZKucffjOZ//JTP7T2XuZfeUmb1zgK/L70sAkaFDBqBUPCrpU70PzGxJ9n/nuvs6d/97SSsl\nLTjD19gkabaZXZh9/AeSfp1zzG8kXZ+9MrRC0i0j9X8AQHIRyACUij+T1GBma7NbZXw8+/wdZvai\nma2V1CXp4YG+QLa7dpuk75vZOmWu8FyWc8xrkv6npGeUmQ7dMNL/RwAkj7l73DUAAACUNDpkAAAA\nMSOQAQAAxIxABgAAEDMCGQAAQMwIZAAAADEjkAEAAMSMQAYAABAzAhkAAEDM/j8w7qMtM4jQGwAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5349267d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate thresholds and accuracies\n",
    "thresholds = np.linspace(0, 1, 1000)\n",
    "accuracies = [np.mean(y_val == (p_val[:, 1] > t).astype(np.int)) for t in thresholds]\n",
    "# f1_scores = [metrics.f1_score(y_val, (p_val[:, 1] > t)) for t in thresholds]\n",
    "# Find optimum threshold\n",
    "optimum_pair = sorted(zip(thresholds, accuracies), key=lambda x: x[1])[-1]\n",
    "print 'Optimum Threshold:', optimum_pair[0]\n",
    "print 'Max. Accuracy:', optimum_pair[1]\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, accuracies)\n",
    "# plt.plot(thresholds, f1_scores)\n",
    "plt.xlabel('Threshold');\n",
    "plt.ylabel('Score');\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
